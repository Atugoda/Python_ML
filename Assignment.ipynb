{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2512 entries, 0 to 2511\n",
      "Data columns (total 16 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   TransactionID            2512 non-null   object \n",
      " 1   AccountID                2512 non-null   object \n",
      " 2   TransactionAmount        2512 non-null   float64\n",
      " 3   TransactionDate          2512 non-null   object \n",
      " 4   TransactionType          2512 non-null   object \n",
      " 5   Location                 2512 non-null   object \n",
      " 6   DeviceID                 2512 non-null   object \n",
      " 7   IP Address               2512 non-null   object \n",
      " 8   MerchantID               2512 non-null   object \n",
      " 9   Channel                  2512 non-null   object \n",
      " 10  CustomerAge              2512 non-null   int64  \n",
      " 11  CustomerOccupation       2512 non-null   object \n",
      " 12  TransactionDuration      2512 non-null   int64  \n",
      " 13  LoginAttempts            2512 non-null   int64  \n",
      " 14  AccountBalance           2512 non-null   float64\n",
      " 15  PreviousTransactionDate  2512 non-null   object \n",
      "dtypes: float64(2), int64(3), object(11)\n",
      "memory usage: 314.1+ KB\n",
      "None\n",
      "       TransactionAmount  CustomerAge  TransactionDuration  LoginAttempts  \\\n",
      "count        2512.000000  2512.000000          2512.000000    2512.000000   \n",
      "mean          297.593778    44.673965           119.643312       1.124602   \n",
      "std           291.946243    17.792198            69.963757       0.602662   \n",
      "min             0.260000    18.000000            10.000000       1.000000   \n",
      "25%            81.885000    27.000000            63.000000       1.000000   \n",
      "50%           211.140000    45.000000           112.500000       1.000000   \n",
      "75%           414.527500    59.000000           161.000000       1.000000   \n",
      "max          1919.110000    80.000000           300.000000       5.000000   \n",
      "\n",
      "       AccountBalance  \n",
      "count     2512.000000  \n",
      "mean      5114.302966  \n",
      "std       3900.942499  \n",
      "min        101.250000  \n",
      "25%       1504.370000  \n",
      "50%       4735.510000  \n",
      "75%       7678.820000  \n",
      "max      14977.990000  \n",
      "Missing values:\n",
      " TransactionID              0\n",
      "AccountID                  0\n",
      "TransactionAmount          0\n",
      "TransactionDate            0\n",
      "TransactionType            0\n",
      "Location                   0\n",
      "DeviceID                   0\n",
      "IP Address                 0\n",
      "MerchantID                 0\n",
      "Channel                    0\n",
      "CustomerAge                0\n",
      "CustomerOccupation         0\n",
      "TransactionDuration        0\n",
      "LoginAttempts              0\n",
      "AccountBalance             0\n",
      "PreviousTransactionDate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/LENOVO/Downloads/bank_transactions_data_2.csv\")\n",
    "\n",
    "# Display basic info\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Count missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values:\\n\", missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values. It was checked to see if there are missing values. But it was mentioned that there are no missing values. Eventhough there are no missing values , I'm going to set the median of the each column to the missing values if they are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after replacement:\n",
      " TransactionID              0\n",
      "AccountID                  0\n",
      "TransactionAmount          0\n",
      "TransactionDate            0\n",
      "TransactionType            0\n",
      "Location                   0\n",
      "DeviceID                   0\n",
      "IP Address                 0\n",
      "MerchantID                 0\n",
      "Channel                    0\n",
      "CustomerAge                0\n",
      "CustomerOccupation         0\n",
      "TransactionDuration        0\n",
      "LoginAttempts              0\n",
      "AccountBalance             0\n",
      "PreviousTransactionDate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values with the median of respective columns\n",
    "data.fillna(data.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"Missing values after replacement:\\n\", data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly shown that there are no missing values now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TransactionAmount', 'CustomerAge', 'TransactionDuration',\n",
      "       'LoginAttempts', 'AccountBalance', 'TransactionID_TX000002',\n",
      "       'TransactionID_TX000003', 'TransactionID_TX000004',\n",
      "       'TransactionID_TX000005', 'TransactionID_TX000006',\n",
      "       ...\n",
      "       'PreviousTransactionDate_2024-11-04 08:12:14',\n",
      "       'PreviousTransactionDate_2024-11-04 08:12:15',\n",
      "       'PreviousTransactionDate_2024-11-04 08:12:16',\n",
      "       'PreviousTransactionDate_2024-11-04 08:12:17',\n",
      "       'PreviousTransactionDate_2024-11-04 08:12:18',\n",
      "       'PreviousTransactionDate_2024-11-04 08:12:19',\n",
      "       'PreviousTransactionDate_2024-11-04 08:12:20',\n",
      "       'PreviousTransactionDate_2024-11-04 08:12:21',\n",
      "       'PreviousTransactionDate_2024-11-04 08:12:22',\n",
      "       'PreviousTransactionDate_2024-11-04 08:12:23'],\n",
      "      dtype='object', length=7298)\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['TimeSinceLastTransaction'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFraud\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Prepare the dataset\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X \u001b[38;5;241m=\u001b[39m data[features]\n\u001b[0;32m     12\u001b[0m y \u001b[38;5;241m=\u001b[39m data[target]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Standardize the features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['TimeSinceLastTransaction'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define relevant columns for logistic regression\n",
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance','CustomerAge','TimeSinceLastTransaction']\n",
    "target = 'Fraud'\n",
    "\n",
    "# Prepare the dataset\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict fraud on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Add predictions to the dataset\n",
    "data['LogReg_Fraud'] = log_reg.predict(X_scaled)\n",
    "data['Fraud'] |= data['LogReg_Fraud']\n",
    "\n",
    "\n",
    "\n",
    "# Visualize fraud vs. non-fraud transactions\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x=data['TransactionAmount'],\n",
    "    y=data['AccountBalance'],\n",
    "    hue=data['LogReg_Fraud'],\n",
    "    palette={1: 'red', 0: 'blue'},\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Logistic Regression Fraud Detection', fontsize=16)\n",
    "plt.xlabel('Transaction Amount', fontsize=14)\n",
    "plt.ylabel('Account Balance', fontsize=14)\n",
    "plt.legend(title='Fraud', labels=['Non-Fraud', 'Fraud'], fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save fraudulent transactions detected by Logistic Regression\n",
    "log_reg_fraud_output_path = '/kaggle/working/log_reg_fraud_transactions.csv'\n",
    "log_reg_fraud_points = data[data['LogReg_Fraud'] == 1]\n",
    "log_reg_fraud_points.to_csv(log_reg_fraud_output_path, index=False)\n",
    "\n",
    "# Summary\n",
    "total_log_reg_fraud_points = log_reg_fraud_points.shape[0]\n",
    "print(f\"Total Fraudulent Transactions Detected by Logistic Regression: {total_log_reg_fraud_points}\")\n",
    "print(f\"Fraudulent transactions saved to: {log_reg_fraud_output_path}\")\n",
    "print(log_reg_fraud_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TransactionID AccountID  TransactionAmount      TransactionDate  \\\n",
      "0      TX000001   AC00128              14.09  2023-04-11 16:29:14   \n",
      "1      TX000002   AC00455             376.24  2023-06-27 16:44:19   \n",
      "2      TX000003   AC00019             126.29  2023-07-10 18:16:08   \n",
      "3      TX000004   AC00070             184.50  2023-05-05 16:32:11   \n",
      "4      TX000005   AC00411              13.45  2023-10-16 17:51:24   \n",
      "\n",
      "  TransactionType   Location DeviceID      IP Address MerchantID Channel  \\\n",
      "0           Debit  San Diego  D000380  162.198.218.92       M015     ATM   \n",
      "1           Debit    Houston  D000051     13.149.61.4       M052     ATM   \n",
      "2           Debit       Mesa  D000235  215.97.143.157       M009  Online   \n",
      "3           Debit    Raleigh  D000187  200.13.225.150       M002  Online   \n",
      "4          Credit    Atlanta  D000308    65.164.3.100       M091  Online   \n",
      "\n",
      "   CustomerAge CustomerOccupation  TransactionDuration  LoginAttempts  \\\n",
      "0           70             Doctor                   81              1   \n",
      "1           68             Doctor                  141              1   \n",
      "2           19            Student                   56              1   \n",
      "3           26            Student                   25              1   \n",
      "4           26            Student                  198              1   \n",
      "\n",
      "   AccountBalance PreviousTransactionDate  \n",
      "0         5112.21     2024-11-04 08:08:08  \n",
      "1        13758.91     2024-11-04 08:09:35  \n",
      "2         1122.35     2024-11-04 08:07:04  \n",
      "3         8569.06     2024-11-04 08:09:06  \n",
      "4         7429.40     2024-11-04 08:06:39  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2512 entries, 0 to 2511\n",
      "Data columns (total 16 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   TransactionID            2512 non-null   object \n",
      " 1   AccountID                2512 non-null   object \n",
      " 2   TransactionAmount        2512 non-null   float64\n",
      " 3   TransactionDate          2512 non-null   object \n",
      " 4   TransactionType          2512 non-null   object \n",
      " 5   Location                 2512 non-null   object \n",
      " 6   DeviceID                 2512 non-null   object \n",
      " 7   IP Address               2512 non-null   object \n",
      " 8   MerchantID               2512 non-null   object \n",
      " 9   Channel                  2512 non-null   object \n",
      " 10  CustomerAge              2512 non-null   int64  \n",
      " 11  CustomerOccupation       2512 non-null   object \n",
      " 12  TransactionDuration      2512 non-null   int64  \n",
      " 13  LoginAttempts            2512 non-null   int64  \n",
      " 14  AccountBalance           2512 non-null   float64\n",
      " 15  PreviousTransactionDate  2512 non-null   object \n",
      "dtypes: float64(2), int64(3), object(11)\n",
      "memory usage: 314.1+ KB\n",
      "None\n",
      "       TransactionAmount  CustomerAge  TransactionDuration  LoginAttempts  \\\n",
      "count        2512.000000  2512.000000          2512.000000    2512.000000   \n",
      "mean          297.593778    44.673965           119.643312       1.124602   \n",
      "std           291.946243    17.792198            69.963757       0.602662   \n",
      "min             0.260000    18.000000            10.000000       1.000000   \n",
      "25%            81.885000    27.000000            63.000000       1.000000   \n",
      "50%           211.140000    45.000000           112.500000       1.000000   \n",
      "75%           414.527500    59.000000           161.000000       1.000000   \n",
      "max          1919.110000    80.000000           300.000000       5.000000   \n",
      "\n",
      "       AccountBalance  \n",
      "count     2512.000000  \n",
      "mean      5114.302966  \n",
      "std       3900.942499  \n",
      "min        101.250000  \n",
      "25%       1504.370000  \n",
      "50%       4735.510000  \n",
      "75%       7678.820000  \n",
      "max      14977.990000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "# Load the dataset\n",
    "file_path = \"C:/Users/LENOVO/Downloads/bank_transactions_data_2.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display initial information about the dataset\n",
    "print(data.head())      # Preview first few rows\n",
    "print(data.info())      # Structure and types of data\n",
    "print(data.describe())  # Summary statistics for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " TransactionID              0\n",
      "AccountID                  0\n",
      "TransactionAmount          0\n",
      "TransactionDate            0\n",
      "TransactionType            0\n",
      "Location                   0\n",
      "DeviceID                   0\n",
      "IP Address                 0\n",
      "MerchantID                 0\n",
      "Channel                    0\n",
      "CustomerAge                0\n",
      "CustomerOccupation         0\n",
      "TransactionDuration        0\n",
      "LoginAttempts              0\n",
      "AccountBalance             0\n",
      "PreviousTransactionDate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", data.isnull().sum())\n",
    "\n",
    "# Fill or drop missing values (example: fill missing numeric columns with median)\n",
    "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].median())\n",
    "\n",
    "# Handle categorical data (example: fill missing with mode)\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    data[col] = data[col].fillna(data[col].mode()[0])\n",
    "\n",
    "# Convert date columns to datetime format (if applicable)\n",
    "if 'date' in data.columns:\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_data = data.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Drop columns with too many missing values (optional)\n",
    "numeric_data = numeric_data.dropna(axis=1, thresh=len(numeric_data) * 0.5)  # Keep columns with >50% non-NaN values\n",
    "\n",
    "# Fill remaining missing values with median (optional)\n",
    "numeric_data = numeric_data.fillna(numeric_data.median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['TimeSinceLastTransaction'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFraud\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Prepare the dataset\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X \u001b[38;5;241m=\u001b[39m data[features]\n\u001b[0;32m     12\u001b[0m y \u001b[38;5;241m=\u001b[39m data[target]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Standardize the features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['TimeSinceLastTransaction'] not in index\""
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define relevant columns for logistic regression\n",
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance','CustomerAge','TimeSinceLastTransaction']\n",
    "target = 'Fraud'\n",
    "\n",
    "# Prepare the dataset\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict fraud on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Add predictions to the dataset\n",
    "data['LogReg_Fraud'] = log_reg.predict(X_scaled)\n",
    "data['Fraud'] |= data['LogReg_Fraud']\n",
    "\n",
    "\n",
    "\n",
    "# Visualize fraud vs. non-fraud transactions\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x=data['TransactionAmount'],\n",
    "    y=data['AccountBalance'],\n",
    "    hue=data['LogReg_Fraud'],\n",
    "    palette={1: 'red', 0: 'blue'},\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Logistic Regression Fraud Detection', fontsize=16)\n",
    "plt.xlabel('Transaction Amount', fontsize=14)\n",
    "plt.ylabel('Account Balance', fontsize=14)\n",
    "plt.legend(title='Fraud', labels=['Non-Fraud', 'Fraud'], fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save fraudulent transactions detected by Logistic Regression\n",
    "log_reg_fraud_output_path = '/kaggle/working/log_reg_fraud_transactions.csv'\n",
    "log_reg_fraud_points = data[data['LogReg_Fraud'] == 1]\n",
    "log_reg_fraud_points.to_csv(log_reg_fraud_output_path, index=False)\n",
    "\n",
    "# Summary\n",
    "total_log_reg_fraud_points = log_reg_fraud_points.shape[0]\n",
    "print(f\"Total Fraudulent Transactions Detected by Logistic Regression: {total_log_reg_fraud_points}\")\n",
    "print(f\"Fraudulent transactions saved to: {log_reg_fraud_output_path}\")\n",
    "print(log_reg_fraud_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['TimeSinceLastTransaction'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFraud\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Prepare the dataset\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m X \u001b[38;5;241m=\u001b[39m data[features]\n\u001b[0;32m     15\u001b[0m y \u001b[38;5;241m=\u001b[39m data[target]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Standardize the features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['TimeSinceLastTransaction'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define relevant columns for logistic regression\n",
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'CustomerAge', 'TimeSinceLastTransaction']\n",
    "target = 'Fraud'\n",
    "\n",
    "# Prepare the dataset\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict fraud on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Add predictions to the dataset\n",
    "data['LogReg_Fraud'] = log_reg.predict(X_scaled)\n",
    "\n",
    "# If you want to set 'Fraud' column to True wherever the model predicts fraud\n",
    "data['Fraud'] = data['Fraud'].fillna(0)  # Assuming Fraud column exists and has NaN values\n",
    "data['Fraud'] |= data['LogReg_Fraud']\n",
    "\n",
    "# Visualize fraud vs. non-fraud transactions\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x=data['TransactionAmount'],\n",
    "    y=data['AccountBalance'],\n",
    "    hue=data['LogReg_Fraud'],\n",
    "    palette={1: 'red', 0: 'blue'},\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Logistic Regression Fraud Detection', fontsize=16)\n",
    "plt.xlabel('Transaction Amount', fontsize=14)\n",
    "plt.ylabel('Account Balance', fontsize=14)\n",
    "plt.legend(title='Fraud', labels=['Non-Fraud', 'Fraud'], fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save fraudulent transactions detected by Logistic Regression\n",
    "log_reg_fraud_output_path = '/kaggle/working/log_reg_fraud_transactions.csv'\n",
    "log_reg_fraud_points = data[data['LogReg_Fraud'] == 1]\n",
    "log_reg_fraud_points.to_csv(log_reg_fraud_output_path, index=False)\n",
    "\n",
    "# Summary\n",
    "total_log_reg_fraud_points = log_reg_fraud_points.shape[0]\n",
    "print(f\"Total Fraudulent Transactions Detected by Logistic Regression: {total_log_reg_fraud_points}\")\n",
    "print(f\"Fraudulent transactions saved to: {log_reg_fraud_output_path}\")\n",
    "print(log_reg_fraud_points.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TransactionID', 'AccountID', 'TransactionAmount', 'TransactionDate',\n",
      "       'TransactionType', 'Location', 'DeviceID', 'IP Address', 'MerchantID',\n",
      "       'Channel', 'CustomerAge', 'CustomerOccupation', 'TransactionDuration',\n",
      "       'LoginAttempts', 'AccountBalance', 'PreviousTransactionDate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TransactionID', 'AccountID', 'TransactionAmount', 'TransactionDate',\n",
      "       'TransactionType', 'Location', 'DeviceID', 'IP Address', 'MerchantID',\n",
      "       'Channel', 'CustomerAge', 'CustomerOccupation', 'TransactionDuration',\n",
      "       'LoginAttempts', 'AccountBalance', 'PreviousTransactionDate'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['TimeSinceLastTransaction'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionAmount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionDuration\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoginAttempts\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccountBalance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerAge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimeSinceLastTransaction\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Make sure these columns exist in your DataFrame, or update them accordingly\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m X \u001b[38;5;241m=\u001b[39m data[features]\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['TimeSinceLastTransaction'] not in index\""
     ]
    }
   ],
   "source": [
    "# Check the columns in your dataset\n",
    "print(data.columns)\n",
    "\n",
    "# Update the feature list if necessary\n",
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'CustomerAge', 'TimeSinceLastTransaction']\n",
    "\n",
    "# Make sure these columns exist in your DataFrame, or update them accordingly\n",
    "X = data[features]  # This should now work if the columns are present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'CustomerAge']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime\n",
    "data['TransactionDate'] = pd.to_datetime(data['TransactionDate'])\n",
    "data['PreviousTransactionDate'] = pd.to_datetime(data['PreviousTransactionDate'])\n",
    "\n",
    "# Calculate time difference in seconds (or any other time unit you prefer)\n",
    "data['TimeSinceLastTransaction'] = (data['TransactionDate'] - data['PreviousTransactionDate']).dt.total_seconds()\n",
    "\n",
    "# Now you can include 'TimeSinceLastTransaction' in your features list\n",
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'CustomerAge', 'TimeSinceLastTransaction']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Train Logistic Regression model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m log_reg \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m log_reg\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Predict fraud on the test set\u001b[39;00m\n\u001b[0;32m     27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m log_reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1207\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1205\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1207\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1208\u001b[0m     X,\n\u001b[0;32m   1209\u001b[0m     y,\n\u001b[0;32m   1210\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1211\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[0;32m   1212\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1213\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1214\u001b[0m )\n\u001b[0;32m   1215\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1163\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[0;32m   1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[1;32m-> 1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1185\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1183\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1184\u001b[0m     y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1185\u001b[0m     _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39mestimator_name)\n\u001b[0;32m   1186\u001b[0m     _ensure_no_complex_data(y)\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_numeric \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare the dataset\n",
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'CustomerAge', 'TimeSinceLastTransaction']  # Update this as needed\n",
    "target = 'TransactionType'\n",
    "\n",
    "X = data[features]\n",
    "y = data[target].map({'Non-Fraud': 0, 'Fraud': 1})  # Encode target variable\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict fraud on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Add predictions to the dataset\n",
    "data['LogReg_Fraud'] = log_reg.predict(X_scaled)\n",
    "data['Fraud'] |= data['LogReg_Fraud']\n",
    "\n",
    "# Visualize fraud vs. non-fraud transactions\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x=data['TransactionAmount'],\n",
    "    y=data['AccountBalance'],\n",
    "    hue=data['LogReg_Fraud'],\n",
    "    palette={1: 'red', 0: 'blue'},\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Logistic Regression Fraud Detection', fontsize=16)\n",
    "plt.xlabel('Transaction Amount', fontsize=14)\n",
    "plt.ylabel('Account Balance', fontsize=14)\n",
    "plt.legend(title='Fraud', labels=['Non-Fraud', 'Fraud'], fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save fraudulent transactions detected by Logistic Regression\n",
    "log_reg_fraud_output_path = '/kaggle/working/log_reg_fraud_transactions.csv'\n",
    "log_reg_fraud_points = data[data['LogReg_Fraud'] == 1]\n",
    "log_reg_fraud_points.to_csv(log_reg_fraud_output_path, index=False)\n",
    "\n",
    "# Summary\n",
    "total_log_reg_fraud_points = log_reg_fraud_points.shape[0]\n",
    "print(f\"Total Fraudulent Transactions Detected by Logistic Regression: {total_log_reg_fraud_points}\")\n",
    "print(f\"Fraudulent transactions saved to: {log_reg_fraud_output_path}\")\n",
    "print(log_reg_fraud_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert ['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'] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1680\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1680\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mcomplex128)\n\u001b[0;32m   1681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1683\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# GH#29941 we get here with object arrays containing strs\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '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'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(data, columns\u001b[38;5;241m=\u001b[39mcategorical_columns, drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Fill missing values in features\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfillna(data\u001b[38;5;241m.\u001b[39mmean())  \u001b[38;5;66;03m# Fill missing numeric features with the mean\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Ensure 'Fraud' is numeric\u001b[39;00m\n\u001b[0;32m     24\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionType\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11539\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11540\u001b[0m     _num_doc,\n\u001b[0;32m  11541\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11554\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11555\u001b[0m ):\n\u001b[1;32m> 11556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11196\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11203\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11154\u001b[0m     nv\u001b[38;5;241m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11159\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11160\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10519\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  10515\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  10517\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  10518\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 10519\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreduce(blk_func)\n\u001b[0;32m  10520\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor(res)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  10521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1534\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1532\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1534\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mreduce(func)\n\u001b[0;32m   1535\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1537\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:339\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 339\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;66;03m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m    343\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[result]])\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10482\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  10480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_reduce(name, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m  10481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 10482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    156\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 421\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    424\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    724\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    726\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 727\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum))\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    730\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1686\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1683\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   1684\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1685\u001b[0m         \u001b[38;5;66;03m# GH#29941 we get here with object arrays containing strs\u001b[39;00m\n\u001b[1;32m-> 1686\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39mimag(x)):\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert ['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'] to numeric"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Drop irrelevant columns\n",
    "columns_to_drop = ['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID']\n",
    "data = data.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "# Encode the target variable\n",
    "data['TransactionType'] = data['TransactionType'].map({'Non-Fraud': 0, 'Fraud': 1})\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "categorical_columns = ['Location', 'MerchantID', 'Channel', 'CustomerOccupation']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Fill missing values in features\n",
    "data = data.fillna(data.mean())  # Fill missing numeric features with the mean\n",
    "\n",
    "# Ensure 'Fraud' is numeric\n",
    "y = data['TransactionType'].astype(int)\n",
    "\n",
    "# Define features for logistic regression (use only numeric columns after encoding)\n",
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'CustomerAge']\n",
    "features.extend([col for col in data.columns if col not in ['TransactionType']])  # Add one-hot encoded columns\n",
    "\n",
    "# Prepare the dataset for modeling\n",
    "X = data[features]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict fraud on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Add predictions to the dataset\n",
    "data['LogReg_Fraud'] = log_reg.predict(X_scaled)\n",
    "\n",
    "# Visualize fraud vs. non-fraud transactions\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x=data['TransactionAmount'],\n",
    "    y=data['AccountBalance'],\n",
    "    hue=data['LogReg_Fraud'],\n",
    "    palette={1: 'red', 0: 'blue'},\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Logistic Regression Fraud Detection', fontsize=16)\n",
    "plt.xlabel('Transaction Amount', fontsize=14)\n",
    "plt.ylabel('Account Balance', fontsize=14)\n",
    "plt.legend(title='Fraud', labels=['Non-Fraud', 'Fraud'], fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save fraudulent transactions detected by Logistic Regression\n",
    "log_reg_fraud_output_path = 'log_reg_fraud_transactions.csv'\n",
    "log_reg_fraud_points = data[data['LogReg_Fraud'] == 1]\n",
    "log_reg_fraud_points.to_csv(log_reg_fraud_output_path, index=False)\n",
    "\n",
    "# Summary\n",
    "total_log_reg_fraud_points = log_reg_fraud_points.shape[0]\n",
    "print(f\"Total Fraudulent Transactions Detected by Logistic Regression: {total_log_reg_fraud_points}\")\n",
    "print(f\"Fraudulent transactions saved to: {log_reg_fraud_output_path}\")\n",
    "print(log_reg_fraud_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Drop irrelevant columns\u001b[39;00m\n\u001b[0;32m     10\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreviousTransactionDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIP Address\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeviceID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcolumns_to_drop, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Encode the target variable\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Ensure that 'TransactionType' is properly mapped and handle missing values before conversion\u001b[39;00m\n\u001b[0;32m     15\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionType\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionType\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNon-Fraud\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFraud\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Drop irrelevant columns\n",
    "columns_to_drop = ['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID']\n",
    "data = data.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "# Encode the target variable\n",
    "# Ensure that 'TransactionType' is properly mapped and handle missing values before conversion\n",
    "data['TransactionType'] = data['TransactionType'].map({'Non-Fraud': 0, 'Fraud': 1})\n",
    "\n",
    "# Check if any missing values in 'TransactionType'\n",
    "if data['TransactionType'].isnull().any():\n",
    "    print(\"Missing values found in 'TransactionType', filling with 0 (Non-Fraud).\")\n",
    "    data['TransactionType'].fillna(0, inplace=True)  # Fill missing values with 0 for non-fraud\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "categorical_columns = ['Location', 'MerchantID', 'Channel', 'CustomerOccupation']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Fill missing values in features\n",
    "data = data.fillna(data.mean())  # Fill missing numeric features with the mean\n",
    "\n",
    "# Ensure 'Fraud' column is numeric and free of issues\n",
    "y = data['TransactionType'].astype(int)\n",
    "\n",
    "# Define features for logistic regression (use only numeric columns after encoding)\n",
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'CustomerAge']\n",
    "features.extend([col for col in data.columns if col not in ['TransactionType']])  # Add one-hot encoded columns\n",
    "\n",
    "# Prepare the dataset for modeling\n",
    "X = data[features]\n",
    "\n",
    "# Check if X contains any non-numeric data\n",
    "if X.select_dtypes(include='object').shape[1] > 0:\n",
    "    print(\"Non-numeric columns detected in features. Converting to numeric.\")\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')  # Convert non-numeric values to NaN\n",
    "\n",
    "# Handle any missing values that may appear after conversion\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict fraud on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Add predictions to the dataset\n",
    "data['LogReg_Fraud'] = log_reg.predict(X_scaled)\n",
    "\n",
    "# Visualize fraud vs. non-fraud transactions\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x=data['TransactionAmount'],\n",
    "    y=data['AccountBalance'],\n",
    "    hue=data['LogReg_Fraud'],\n",
    "    palette={1: 'red', 0: 'blue'},\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Logistic Regression Fraud Detection', fontsize=16)\n",
    "plt.xlabel('Transaction Amount', fontsize=14)\n",
    "plt.ylabel('Account Balance', fontsize=14)\n",
    "plt.legend(title='Fraud', labels=['Non-Fraud', 'Fraud'], fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save fraudulent transactions detected by Logistic Regression\n",
    "log_reg_fraud_output_path = 'log_reg_fraud_transactions.csv'\n",
    "log_reg_fraud_points = data[data['LogReg_Fraud'] == 1]\n",
    "log_reg_fraud_points.to_csv(log_reg_fraud_output_path, index=False)\n",
    "\n",
    "# Summary\n",
    "total_log_reg_fraud_points = log_reg_fraud_points.shape[0]\n",
    "print(f\"Total Fraudulent Transactions Detected by Logistic Regression: {total_log_reg_fraud_points}\")\n",
    "print(f\"Fraudulent transactions saved to: {log_reg_fraud_output_path}\")\n",
    "print(log_reg_fraud_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.strip()  # Remove any leading/trailing spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns if they exist\n",
    "columns_to_drop = ['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID']\n",
    "data = data.drop(columns=[col for col in columns_to_drop if col in data.columns], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Drop irrelevant columns\u001b[39;00m\n\u001b[0;32m     10\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreviousTransactionDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIP Address\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeviceID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcolumns_to_drop, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Encode the target variable\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Ensure that 'TransactionType' is properly mapped and handle missing values before conversion\u001b[39;00m\n\u001b[0;32m     15\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionType\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionType\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNon-Fraud\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFraud\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Drop irrelevant columns\n",
    "columns_to_drop = ['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID']\n",
    "data = data.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "# Encode the target variable\n",
    "# Ensure that 'TransactionType' is properly mapped and handle missing values before conversion\n",
    "data['TransactionType'] = data['TransactionType'].map({'Non-Fraud': 0, 'Fraud': 1})\n",
    "\n",
    "# Check if any missing values in 'TransactionType'\n",
    "if data['TransactionType'].isnull().any():\n",
    "    print(\"Missing values found in 'TransactionType', filling with 0 (Non-Fraud).\")\n",
    "    data['TransactionType'].fillna(0, inplace=True)  # Fill missing values with 0 for non-fraud\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "categorical_columns = ['Location', 'MerchantID', 'Channel', 'CustomerOccupation']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Fill missing values in features\n",
    "data = data.fillna(data.mean())  # Fill missing numeric features with the mean\n",
    "\n",
    "# Ensure 'Fraud' column is numeric and free of issues\n",
    "y = data['TransactionType'].astype(int)\n",
    "\n",
    "# Define features for logistic regression (use only numeric columns after encoding)\n",
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'CustomerAge']\n",
    "features.extend([col for col in data.columns if col not in ['TransactionType']])  # Add one-hot encoded columns\n",
    "\n",
    "# Prepare the dataset for modeling\n",
    "X = data[features]\n",
    "\n",
    "# Check if X contains any non-numeric data\n",
    "if X.select_dtypes(include='object').shape[1] > 0:\n",
    "    print(\"Non-numeric columns detected in features. Converting to numeric.\")\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')  # Convert non-numeric values to NaN\n",
    "\n",
    "# Handle any missing values that may appear after conversion\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict fraud on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Add predictions to the dataset\n",
    "data['LogReg_Fraud'] = log_reg.predict(X_scaled)\n",
    "\n",
    "# Visualize fraud vs. non-fraud transactions\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x=data['TransactionAmount'],\n",
    "    y=data['AccountBalance'],\n",
    "    hue=data['LogReg_Fraud'],\n",
    "    palette={1: 'red', 0: 'blue'},\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Logistic Regression Fraud Detection', fontsize=16)\n",
    "plt.xlabel('Transaction Amount', fontsize=14)\n",
    "plt.ylabel('Account Balance', fontsize=14)\n",
    "plt.legend(title='Fraud', labels=['Non-Fraud', 'Fraud'], fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save fraudulent transactions detected by Logistic Regression\n",
    "log_reg_fraud_output_path = 'log_reg_fraud_transactions.csv'\n",
    "log_reg_fraud_points = data[data['LogReg_Fraud'] == 1]\n",
    "log_reg_fraud_points.to_csv(log_reg_fraud_output_path, index=False)\n",
    "\n",
    "# Summary\n",
    "total_log_reg_fraud_points = log_reg_fraud_points.shape[0]\n",
    "print(f\"Total Fraudulent Transactions Detected by Logistic Regression: {total_log_reg_fraud_points}\")\n",
    "print(f\"Fraudulent transactions saved to: {log_reg_fraud_output_path}\")\n",
    "print(log_reg_fraud_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID']\n",
    "columns_to_drop = [col for col in columns_to_drop if col in data.columns]  # Drop only existing columns\n",
    "data = data.drop(columns=columns_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Drop irrelevant columns\u001b[39;00m\n\u001b[0;32m     10\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreviousTransactionDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIP Address\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeviceID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcolumns_to_drop, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Encode the target variable\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Ensure that 'TransactionType' is properly mapped and handle missing values before conversion\u001b[39;00m\n\u001b[0;32m     15\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionType\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransactionType\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNon-Fraud\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFraud\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Drop irrelevant columns\n",
    "columns_to_drop = ['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID']\n",
    "data = data.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "# Encode the target variable\n",
    "# Ensure that 'TransactionType' is properly mapped and handle missing values before conversion\n",
    "data['TransactionType'] = data['TransactionType'].map({'Non-Fraud': 0, 'Fraud': 1})\n",
    "\n",
    "# Check if any missing values in 'TransactionType'\n",
    "if data['TransactionType'].isnull().any():\n",
    "    print(\"Missing values found in 'TransactionType', filling with 0 (Non-Fraud).\")\n",
    "    data['TransactionType'].fillna(0, inplace=True)  # Fill missing values with 0 for non-fraud\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "categorical_columns = ['Location', 'MerchantID', 'Channel', 'CustomerOccupation']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Fill missing values in features\n",
    "data = data.fillna(data.mean())  # Fill missing numeric features with the mean\n",
    "\n",
    "# Ensure 'Fraud' column is numeric and free of issues\n",
    "y = data['TransactionType'].astype(int)\n",
    "\n",
    "# Define features for logistic regression (use only numeric columns after encoding)\n",
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'CustomerAge']\n",
    "features.extend([col for col in data.columns if col not in ['TransactionType']])  # Add one-hot encoded columns\n",
    "\n",
    "# Prepare the dataset for modeling\n",
    "X = data[features]\n",
    "\n",
    "# Check if X contains any non-numeric data\n",
    "if X.select_dtypes(include='object').shape[1] > 0:\n",
    "    print(\"Non-numeric columns detected in features. Converting to numeric.\")\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')  # Convert non-numeric values to NaN\n",
    "\n",
    "# Handle any missing values that may appear after conversion\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict fraud on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Add predictions to the dataset\n",
    "data['LogReg_Fraud'] = log_reg.predict(X_scaled)\n",
    "\n",
    "# Visualize fraud vs. non-fraud transactions\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x=data['TransactionAmount'],\n",
    "    y=data['AccountBalance'],\n",
    "    hue=data['LogReg_Fraud'],\n",
    "    palette={1: 'red', 0: 'blue'},\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Logistic Regression Fraud Detection', fontsize=16)\n",
    "plt.xlabel('Transaction Amount', fontsize=14)\n",
    "plt.ylabel('Account Balance', fontsize=14)\n",
    "plt.legend(title='Fraud', labels=['Non-Fraud', 'Fraud'], fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save fraudulent transactions detected by Logistic Regression\n",
    "log_reg_fraud_output_path = 'log_reg_fraud_transactions.csv'\n",
    "log_reg_fraud_points = data[data['LogReg_Fraud'] == 1]\n",
    "log_reg_fraud_points.to_csv(log_reg_fraud_output_path, index=False)\n",
    "\n",
    "# Summary\n",
    "total_log_reg_fraud_points = log_reg_fraud_points.shape[0]\n",
    "print(f\"Total Fraudulent Transactions Detected by Logistic Regression: {total_log_reg_fraud_points}\")\n",
    "print(f\"Fraudulent transactions saved to: {log_reg_fraud_output_path}\")\n",
    "print(log_reg_fraud_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[23], line 24\u001b[0m\n",
      "\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Train Logistic Regression model\u001b[39;00m\n",
      "\u001b[0;32m     23\u001b[0m log_reg \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;32m---> 24\u001b[0m log_reg\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Predict fraud on the test set\u001b[39;00m\n",
      "\u001b[0;32m     27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m log_reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n",
      "\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[0;32m   1149\u001b[0m     )\n",
      "\u001b[0;32m   1150\u001b[0m ):\n",
      "\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1207\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n",
      "\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m   1205\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n",
      "\u001b[1;32m-> 1207\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n",
      "\u001b[0;32m   1208\u001b[0m     X,\n",
      "\u001b[0;32m   1209\u001b[0m     y,\n",
      "\u001b[0;32m   1210\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m   1211\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n",
      "\u001b[0;32m   1212\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m   1213\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n",
      "\u001b[0;32m   1214\u001b[0m )\n",
      "\u001b[0;32m   1215\u001b[0m check_classification_targets(y)\n",
      "\u001b[0;32m   1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n",
      "\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n",
      "\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n",
      "\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1163\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n",
      "\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   1145\u001b[0m     )\n",
      "\u001b[0;32m   1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n",
      "\u001b[0;32m   1148\u001b[0m     X,\n",
      "\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m   1161\u001b[0m )\n",
      "\u001b[1;32m-> 1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n",
      "\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1185\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n",
      "\u001b[0;32m   1183\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "\u001b[0;32m   1184\u001b[0m     y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;32m-> 1185\u001b[0m     _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39mestimator_name)\n",
      "\u001b[0;32m   1186\u001b[0m     _ensure_no_complex_data(y)\n",
      "\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_numeric \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n",
      "\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n",
      "\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n",
      "\u001b[0;32m    125\u001b[0m     X,\n",
      "\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n",
      "\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n",
      "\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n",
      "\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n",
      "\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n",
      "\u001b[0;32m    131\u001b[0m )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n",
      "\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n",
      "\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n",
      "\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n",
      "\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    172\u001b[0m     )\n",
      "\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare the dataset\n",
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'CustomerAge', 'TimeSinceLastTransaction']  # Update this as needed\n",
    "target = 'TransactionType'\n",
    "\n",
    "X = data[features]\n",
    "y = data[target].map({'Non-Fraud': 0, 'Fraud': 1})  # Encode target variable\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict fraud on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Add predictions to the dataset\n",
    "data['LogReg_Fraud'] = log_reg.predict(X_scaled)\n",
    "data['Fraud'] |= data['LogReg_Fraud']\n",
    "\n",
    "# Visualize fraud vs. non-fraud transactions\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x=data['TransactionAmount'],\n",
    "    y=data['AccountBalance'],\n",
    "    hue=data['LogReg_Fraud'],\n",
    "    palette={1: 'red', 0: 'blue'},\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Logistic Regression Fraud Detection', fontsize=16)\n",
    "plt.xlabel('Transaction Amount', fontsize=14)\n",
    "plt.ylabel('Account Balance', fontsize=14)\n",
    "plt.legend(title='Fraud', labels=['Non-Fraud', 'Fraud'], fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save fraudulent transactions detected by Logistic Regression\n",
    "log_reg_fraud_output_path = '/kaggle/working/log_reg_fraud_transactions.csv'\n",
    "log_reg_fraud_points = data[data['LogReg_Fraud'] == 1]\n",
    "log_reg_fraud_points.to_csv(log_reg_fraud_output_path, index=False)\n",
    "\n",
    "# Summary\n",
    "total_log_reg_fraud_points = log_reg_fraud_points.shape[0]\n",
    "print(f\"Total Fraudulent Transactions Detected by Logistic Regression: {total_log_reg_fraud_points}\")\n",
    "print(f\"Fraudulent transactions saved to: {log_reg_fraud_output_path}\")\n",
    "print(log_reg_fraud_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[23], line 24\u001b[0m\n",
      "\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Train Logistic Regression model\u001b[39;00m\n",
      "\u001b[0;32m     23\u001b[0m log_reg \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;32m---> 24\u001b[0m log_reg\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Predict fraud on the test set\u001b[39;00m\n",
      "\u001b[0;32m     27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m log_reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n",
      "\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[0;32m   1149\u001b[0m     )\n",
      "\u001b[0;32m   1150\u001b[0m ):\n",
      "\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1207\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n",
      "\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m   1205\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n",
      "\u001b[1;32m-> 1207\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n",
      "\u001b[0;32m   1208\u001b[0m     X,\n",
      "\u001b[0;32m   1209\u001b[0m     y,\n",
      "\u001b[0;32m   1210\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m   1211\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n",
      "\u001b[0;32m   1212\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m   1213\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n",
      "\u001b[0;32m   1214\u001b[0m )\n",
      "\u001b[0;32m   1215\u001b[0m check_classification_targets(y)\n",
      "\u001b[0;32m   1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n",
      "\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n",
      "\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n",
      "\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1163\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n",
      "\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   1145\u001b[0m     )\n",
      "\u001b[0;32m   1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n",
      "\u001b[0;32m   1148\u001b[0m     X,\n",
      "\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m   1161\u001b[0m )\n",
      "\u001b[1;32m-> 1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n",
      "\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1185\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n",
      "\u001b[0;32m   1183\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "\u001b[0;32m   1184\u001b[0m     y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;32m-> 1185\u001b[0m     _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39mestimator_name)\n",
      "\u001b[0;32m   1186\u001b[0m     _ensure_no_complex_data(y)\n",
      "\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_numeric \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n",
      "\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n",
      "\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n",
      "\u001b[0;32m    125\u001b[0m     X,\n",
      "\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n",
      "\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n",
      "\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n",
      "\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n",
      "\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n",
      "\u001b[0;32m    131\u001b[0m )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n",
      "\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n",
      "\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n",
      "\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n",
      "\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    172\u001b[0m     )\n",
      "\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare the dataset\n",
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'CustomerAge', 'TimeSinceLastTransaction']  # Update this as needed\n",
    "target = 'TransactionType'\n",
    "\n",
    "X = data[features]\n",
    "y = data[target].map({'Non-Fraud': 0, 'Fraud': 1})  # Encode target variable\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict fraud on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Add predictions to the dataset\n",
    "data['LogReg_Fraud'] = log_reg.predict(X_scaled)\n",
    "data['Fraud'] |= data['LogReg_Fraud']\n",
    "\n",
    "# Visualize fraud vs. non-fraud transactions\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x=data['TransactionAmount'],\n",
    "    y=data['AccountBalance'],\n",
    "    hue=data['LogReg_Fraud'],\n",
    "    palette={1: 'red', 0: 'blue'},\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Logistic Regression Fraud Detection', fontsize=16)\n",
    "plt.xlabel('Transaction Amount', fontsize=14)\n",
    "plt.ylabel('Account Balance', fontsize=14)\n",
    "plt.legend(title='Fraud', labels=['Non-Fraud', 'Fraud'], fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save fraudulent transactions detected by Logistic Regression\n",
    "log_reg_fraud_output_path = '/kaggle/working/log_reg_fraud_transactions.csv'\n",
    "log_reg_fraud_points = data[data['LogReg_Fraud'] == 1]\n",
    "log_reg_fraud_points.to_csv(log_reg_fraud_output_path, index=False)\n",
    "\n",
    "# Summary\n",
    "total_log_reg_fraud_points = log_reg_fraud_points.shape[0]\n",
    "print(f\"Total Fraudulent Transactions Detected by Logistic Regression: {total_log_reg_fraud_points}\")\n",
    "print(f\"Fraudulent transactions saved to: {log_reg_fraud_output_path}\")\n",
    "print(log_reg_fraud_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns not found in DataFrame: ['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID']\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID']\n",
    "missing_cols = [col for col in columns_to_drop if col not in data.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Columns not found in DataFrame: {missing_cols}\")\n",
    "data = data.drop(columns=[col for col in columns_to_drop if col in data.columns], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'AccountID': 9\n",
      "'TransactionAmount': 17\n",
      "'TransactionType': 15\n",
      "'CustomerAge': 11\n",
      "'TransactionDuration': 19\n",
      "'LoginAttempts': 13\n",
      "'AccountBalance': 14\n",
      "'TimeSinceLastTransaction': 24\n",
      "'Location_Atlanta': 16\n",
      "'Location_Austin': 15\n",
      "'Location_Baltimore': 18\n",
      "'Location_Boston': 15\n",
      "'Location_Charlotte': 18\n",
      "'Location_Chicago': 16\n",
      "'Location_Colorado Springs': 25\n",
      "'Location_Columbus': 17\n",
      "'Location_Dallas': 15\n",
      "'Location_Denver': 15\n",
      "'Location_Detroit': 16\n",
      "'Location_El Paso': 16\n",
      "'Location_Fort Worth': 19\n",
      "'Location_Fresno': 15\n",
      "'Location_Houston': 16\n",
      "'Location_Indianapolis': 21\n",
      "'Location_Jacksonville': 21\n",
      "'Location_Kansas City': 20\n",
      "'Location_Las Vegas': 18\n",
      "'Location_Los Angeles': 20\n",
      "'Location_Louisville': 19\n",
      "'Location_Memphis': 16\n",
      "'Location_Mesa': 13\n",
      "'Location_Miami': 14\n",
      "'Location_Milwaukee': 18\n",
      "'Location_Nashville': 18\n",
      "'Location_New York': 17\n",
      "'Location_Oklahoma City': 22\n",
      "'Location_Omaha': 14\n",
      "'Location_Philadelphia': 21\n",
      "'Location_Phoenix': 16\n",
      "'Location_Portland': 17\n",
      "'Location_Raleigh': 16\n",
      "'Location_Sacramento': 19\n",
      "'Location_San Antonio': 20\n",
      "'Location_San Diego': 18\n",
      "'Location_San Francisco': 22\n",
      "'Location_San Jose': 17\n",
      "'Location_Seattle': 16\n",
      "'Location_Tucson': 15\n",
      "'Location_Virginia Beach': 23\n",
      "'Location_Washington': 19\n",
      "'MerchantID_M002': 15\n",
      "'MerchantID_M003': 15\n",
      "'MerchantID_M004': 15\n",
      "'MerchantID_M005': 15\n",
      "'MerchantID_M006': 15\n",
      "'MerchantID_M007': 15\n",
      "'MerchantID_M008': 15\n",
      "'MerchantID_M009': 15\n",
      "'MerchantID_M010': 15\n",
      "'MerchantID_M011': 15\n",
      "'MerchantID_M012': 15\n",
      "'MerchantID_M013': 15\n",
      "'MerchantID_M014': 15\n",
      "'MerchantID_M015': 15\n",
      "'MerchantID_M016': 15\n",
      "'MerchantID_M017': 15\n",
      "'MerchantID_M018': 15\n",
      "'MerchantID_M019': 15\n",
      "'MerchantID_M020': 15\n",
      "'MerchantID_M021': 15\n",
      "'MerchantID_M022': 15\n",
      "'MerchantID_M023': 15\n",
      "'MerchantID_M024': 15\n",
      "'MerchantID_M025': 15\n",
      "'MerchantID_M026': 15\n",
      "'MerchantID_M027': 15\n",
      "'MerchantID_M028': 15\n",
      "'MerchantID_M029': 15\n",
      "'MerchantID_M030': 15\n",
      "'MerchantID_M031': 15\n",
      "'MerchantID_M032': 15\n",
      "'MerchantID_M033': 15\n",
      "'MerchantID_M034': 15\n",
      "'MerchantID_M035': 15\n",
      "'MerchantID_M036': 15\n",
      "'MerchantID_M037': 15\n",
      "'MerchantID_M038': 15\n",
      "'MerchantID_M039': 15\n",
      "'MerchantID_M040': 15\n",
      "'MerchantID_M041': 15\n",
      "'MerchantID_M042': 15\n",
      "'MerchantID_M043': 15\n",
      "'MerchantID_M044': 15\n",
      "'MerchantID_M045': 15\n",
      "'MerchantID_M046': 15\n",
      "'MerchantID_M047': 15\n",
      "'MerchantID_M048': 15\n",
      "'MerchantID_M049': 15\n",
      "'MerchantID_M050': 15\n",
      "'MerchantID_M051': 15\n",
      "'MerchantID_M052': 15\n",
      "'MerchantID_M053': 15\n",
      "'MerchantID_M054': 15\n",
      "'MerchantID_M055': 15\n",
      "'MerchantID_M056': 15\n",
      "'MerchantID_M057': 15\n",
      "'MerchantID_M058': 15\n",
      "'MerchantID_M059': 15\n",
      "'MerchantID_M060': 15\n",
      "'MerchantID_M061': 15\n",
      "'MerchantID_M062': 15\n",
      "'MerchantID_M063': 15\n",
      "'MerchantID_M064': 15\n",
      "'MerchantID_M065': 15\n",
      "'MerchantID_M066': 15\n",
      "'MerchantID_M067': 15\n",
      "'MerchantID_M068': 15\n",
      "'MerchantID_M069': 15\n",
      "'MerchantID_M070': 15\n",
      "'MerchantID_M071': 15\n",
      "'MerchantID_M072': 15\n",
      "'MerchantID_M073': 15\n",
      "'MerchantID_M074': 15\n",
      "'MerchantID_M075': 15\n",
      "'MerchantID_M076': 15\n",
      "'MerchantID_M077': 15\n",
      "'MerchantID_M078': 15\n",
      "'MerchantID_M079': 15\n",
      "'MerchantID_M080': 15\n",
      "'MerchantID_M081': 15\n",
      "'MerchantID_M082': 15\n",
      "'MerchantID_M083': 15\n",
      "'MerchantID_M084': 15\n",
      "'MerchantID_M085': 15\n",
      "'MerchantID_M086': 15\n",
      "'MerchantID_M087': 15\n",
      "'MerchantID_M088': 15\n",
      "'MerchantID_M089': 15\n",
      "'MerchantID_M090': 15\n",
      "'MerchantID_M091': 15\n",
      "'MerchantID_M092': 15\n",
      "'MerchantID_M093': 15\n",
      "'MerchantID_M094': 15\n",
      "'MerchantID_M095': 15\n",
      "'MerchantID_M096': 15\n",
      "'MerchantID_M097': 15\n",
      "'MerchantID_M098': 15\n",
      "'MerchantID_M099': 15\n",
      "'MerchantID_M100': 15\n",
      "'Channel_Branch': 14\n",
      "'Channel_Online': 14\n",
      "'CustomerOccupation_Engineer': 27\n",
      "'CustomerOccupation_Retired': 26\n",
      "'CustomerOccupation_Student': 26\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    print(f\"'{col}': {len(col)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: []\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID']\n",
    "# Check which columns exist in the DataFrame\n",
    "columns_to_drop_existing = [col for col in columns_to_drop if col in data.columns]\n",
    "# Drop only those that exist\n",
    "data = data.drop(columns=columns_to_drop_existing, axis=1)\n",
    "print(f\"Dropped columns: {columns_to_drop_existing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Location', 'MerchantID', 'Channel', 'CustomerOccupation'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# One-hot encode categorical columns\u001b[39;00m\n\u001b[0;32m     23\u001b[0m categorical_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMerchantID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChannel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerOccupation\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(data, columns\u001b[38;5;241m=\u001b[39mcategorical_columns, drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Fill missing values in features\u001b[39;00m\n\u001b[0;32m     27\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfillna(data\u001b[38;5;241m.\u001b[39mmean())  \u001b[38;5;66;03m# Fill missing numeric features with the mean\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:158\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a list-like for parameter `columns`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     data_to_encode \u001b[38;5;241m=\u001b[39m data[columns]\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_len\u001b[39m(item, name):\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5937\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Location', 'MerchantID', 'Channel', 'CustomerOccupation'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Drop irrelevant columns\n",
    "columns_to_drop = ['TransactionID', 'PreviousTransactionDate', 'TransactionDate', 'IP Address', 'DeviceID']\n",
    "data = data.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "# Encode the target variable\n",
    "# Ensure that 'TransactionType' is properly mapped and handle missing values before conversion\n",
    "data['TransactionType'] = data['TransactionType'].map({'Non-Fraud': 0, 'Fraud': 1})\n",
    "\n",
    "# Check if any missing values in 'TransactionType'\n",
    "if data['TransactionType'].isnull().any():\n",
    "    print(\"Missing values found in 'TransactionType', filling with 0 (Non-Fraud).\")\n",
    "    data['TransactionType'].fillna(0, inplace=True)  # Fill missing values with 0 for non-fraud\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "categorical_columns = ['Location', 'MerchantID', 'Channel', 'CustomerOccupation']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Fill missing values in features\n",
    "data = data.fillna(data.mean())  # Fill missing numeric features with the mean\n",
    "\n",
    "# Ensure 'Fraud' column is numeric and free of issues\n",
    "y = data['TransactionType'].astype(int)\n",
    "\n",
    "# Define features for logistic regression (use only numeric columns after encoding)\n",
    "features = ['TransactionAmount', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'CustomerAge']\n",
    "features.extend([col for col in data.columns if col not in ['TransactionType']])  # Add one-hot encoded columns\n",
    "\n",
    "# Prepare the dataset for modeling\n",
    "X = data[features]\n",
    "\n",
    "# Check if X contains any non-numeric data\n",
    "if X.select_dtypes(include='object').shape[1] > 0:\n",
    "    print(\"Non-numeric columns detected in features. Converting to numeric.\")\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')  # Convert non-numeric values to NaN\n",
    "\n",
    "# Handle any missing values that may appear after conversion\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict fraud on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Add predictions to the dataset\n",
    "data['LogReg_Fraud'] = log_reg.predict(X_scaled)\n",
    "\n",
    "# Visualize fraud vs. non-fraud transactions\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x=data['TransactionAmount'],\n",
    "    y=data['AccountBalance'],\n",
    "    hue=data['LogReg_Fraud'],\n",
    "    palette={1: 'red', 0: 'blue'},\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Logistic Regression Fraud Detection', fontsize=16)\n",
    "plt.xlabel('Transaction Amount', fontsize=14)\n",
    "plt.ylabel('Account Balance', fontsize=14)\n",
    "plt.legend(title='Fraud', labels=['Non-Fraud', 'Fraud'], fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save fraudulent transactions detected by Logistic Regression\n",
    "log_reg_fraud_output_path = 'log_reg_fraud_transactions.csv'\n",
    "log_reg_fraud_points = data[data['LogReg_Fraud'] == 1]\n",
    "log_reg_fraud_points.to_csv(log_reg_fraud_output_path, index=False)\n",
    "\n",
    "# Summary\n",
    "total_log_reg_fraud_points = log_reg_fraud_points.shape[0]\n",
    "print(f\"Total Fraudulent Transactions Detected by Logistic Regression: {total_log_reg_fraud_points}\")\n",
    "print(f\"Fraudulent transactions saved to: {log_reg_fraud_output_path}\")\n",
    "print(log_reg_fraud_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profession</th>\n",
       "      <th>Income</th>\n",
       "      <th>Credit_card_number</th>\n",
       "      <th>Expiry</th>\n",
       "      <th>Security_Code</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nurse</td>\n",
       "      <td>45795.0</td>\n",
       "      <td>9144527053068335</td>\n",
       "      <td>01/25</td>\n",
       "      <td>410.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nurse</td>\n",
       "      <td>30860.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/29</td>\n",
       "      <td>373.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Artist</td>\n",
       "      <td>133694.0</td>\n",
       "      <td>8087054594544322</td>\n",
       "      <td>07/28</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lawyer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3818004552689757</td>\n",
       "      <td>06/29</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lawyer</td>\n",
       "      <td>140268.0</td>\n",
       "      <td>4793979148350804</td>\n",
       "      <td>06/27</td>\n",
       "      <td>820.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Profession    Income Credit_card_number Expiry  Security_Code  Fraud\n",
       "0      Nurse   45795.0   9144527053068335  01/25          410.0      0\n",
       "1      Nurse   30860.0                NaN  02/29          373.0      0\n",
       "2     Artist  133694.0   8087054594544322  07/28          134.0      0\n",
       "3     Lawyer       NaN   3818004552689757  06/29          316.0      0\n",
       "4     Lawyer  140268.0   4793979148350804  06/27          820.0      0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import choice\n",
    "\n",
    "# Generate a dataset with 800 rows\n",
    "np.random.seed(42)\n",
    "\n",
    "# Data for professions\n",
    "professions = ['Doctor', 'Lawyer', 'Engineer', 'Teacher', 'Artist', 'Nurse']\n",
    "\n",
    "# Generate random data for each column\n",
    "data = {\n",
    "    'Profession': [choice(professions) for _ in range(800)],\n",
    "    'Income': np.random.randint(30000, 150000, 800),\n",
    "    'Credit_card_number': [''.join([str(np.random.randint(0, 10)) for _ in range(16)]) for _ in range(800)],\n",
    "    'Expiry': [f\"{np.random.randint(1, 13):02}/{np.random.randint(21, 30)}\" for _ in range(800)],\n",
    "    'Security_Code': [np.random.randint(100, 999) for _ in range(800)],\n",
    "    'Fraud': np.random.choice([0, 1], 800, p=[0.85, 0.15])  # Imbalanced classes, 15% fraud\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce some missing values randomly\n",
    "for column in ['Income', 'Credit_card_number', 'Expiry', 'Security_Code']:\n",
    "    missing_indices = np.random.choice(df.index, size=int(0.1 * len(df)), replace=False)\n",
    "    df.loc[missing_indices, column] = np.nan\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_check_n_features' from 'sklearn.utils.validation' (c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Ensemble-based methods for classification, regression and anomaly detection.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bagging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaggingClassifier, BaggingRegressor\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEnsemble\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_forest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     ExtraTreesClassifier,\n\u001b[0;32m     10\u001b[0m     ExtraTreesRegressor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     RandomTreesEmbedding,\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassifierMixin, RegressorMixin, _fit_context\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, r2_score\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier, DecisionTreeRegressor\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     Bunch,\n\u001b[0;32m     21\u001b[0m     _safe_indexing,\n\u001b[0;32m     22\u001b[0m     check_random_state,\n\u001b[0;32m     23\u001b[0m     column_or_1d,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_mask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m indices_to_mask\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Decision tree based models for classification and regression.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     BaseDecisionTree,\n\u001b[0;32m      8\u001b[0m     DecisionTreeClassifier,\n\u001b[0;32m      9\u001b[0m     DecisionTreeRegressor,\n\u001b[0;32m     10\u001b[0m     ExtraTreeClassifier,\n\u001b[0;32m     11\u001b[0m     ExtraTreeRegressor,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_graphviz, export_text, plot_tree\n\u001b[0;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseDecisionTree\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecisionTreeClassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport_text\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hidden, Interval, RealNotInt, StrOptions\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     _assert_all_finite_element_wise,\n\u001b[0;32m     34\u001b[0m     _check_n_features,\n\u001b[0;32m     35\u001b[0m     _check_sample_weight,\n\u001b[0;32m     36\u001b[0m     assert_all_finite,\n\u001b[0;32m     37\u001b[0m     check_is_fitted,\n\u001b[0;32m     38\u001b[0m     validate_data,\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _criterion, _splitter, _tree\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_criterion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Criterion\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_check_n_features' from 'sklearn.utils.validation' (c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('fraud-detection-dataset.csv')\n",
    "\n",
    "# Check missing values\n",
    "print(\"Missing values before handling:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "# Fill missing categorical column 'Profession' with the mode\n",
    "data['Profession'] = data['Profession'].fillna(data['Profession'].mode()[0])\n",
    "\n",
    "# Fill missing numerical columns with the mean\n",
    "data['Income'] = data['Income'].fillna(data['Income'].mean())\n",
    "data['Security_Code'] = data['Security_Code'].fillna(data['Security_Code'].mean())\n",
    "\n",
    "# Fill missing target column 'Fraud' with the mode\n",
    "data['Fraud'] = data['Fraud'].fillna(data['Fraud'].mode()[0])\n",
    "\n",
    "# Fill missing 'Expiry' with the mode\n",
    "data['Expiry'] = data['Expiry'].fillna(data['Expiry'].mode()[0])\n",
    "\n",
    "# Feature Engineering: Create 'Months_to_expiry' column\n",
    "current_date = datetime.now()\n",
    "\n",
    "def calculate_months_to_expiry(expiry):\n",
    "    exp_month, exp_year = map(int, expiry.split(\"/\"))\n",
    "    expiry_date = datetime(year=2000 + exp_year, month=exp_month, day=1)\n",
    "    return max(0, (expiry_date.year - current_date.year) * 12 + (expiry_date.month - current_date.month))\n",
    "\n",
    "data['Months_to_expiry'] = data['Expiry'].apply(calculate_months_to_expiry)\n",
    "\n",
    "# One-hot encode the 'Profession' column\n",
    "data = pd.get_dummies(data, columns=['Profession'], drop_first=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['Credit_card_number', 'Expiry'])\n",
    "\n",
    "# Recheck for any remaining missing values\n",
    "print(\"Missing values after handling:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data.drop(columns=['Fraud'])\n",
    "y = data['Fraud']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Random Forest model using Gini index\n",
    "model = RandomForestClassifier(criterion='gini', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance visualization\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feature_importances.sort_values(ascending=False).plot(kind='bar', title='Feature Importance', figsize=(10, 6))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
